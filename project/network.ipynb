{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "** 02805 Social graphs and interactions **\n",
    "\n",
    "# Network Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "# IPython global cell magic\n",
    "%reset\n",
    "%matplotlib inline\n",
    "\n",
    "# import all necessary packages\n",
    "import bs4 # HTML parser\n",
    "from collections import Counter, OrderedDict # counting elements and ordering keys in dictionaries\n",
    "import community # python-louvain package\n",
    "import datetime # handle date objects\n",
    "import dateparser # parse any (also foreign) date format to object: https://pypi.python.org/pypi/dateparser\n",
    "from __future__ import division # all numbers are float\n",
    "import gc # garbage collector\n",
    "import geoplotlib # plot points on tiled maps\n",
    "from geoplotlib.utils import BoundingBox\n",
    "import geopy # get geo location according to addresses\n",
    "from geopy.exc import GeocoderServiceError\n",
    "from infomap import infomap # python infomap algorithm, needs to be in same directory\n",
    "import itertools # iterators for efficient looping\n",
    "import json # JSON parser\n",
    "import math # math operations\n",
    "from matplotlib import pyplot as plt # plotting figures\n",
    "import mwparserfromhell # parse MediaWiki syntax: https://github.com/earwig/mwparserfromhell\n",
    "from nameparser import HumanName # parse a human name\n",
    "import networkx as nx # networks creation library\n",
    "import nltk # natural language processing\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import operator # efficient operator functions\n",
    "import os # operating system operations, e.g.: with files and folders\n",
    "import pandas as pd # use easy-to-use data frames for data analysis\n",
    "import pickle # python data structures as files\n",
    "from pprint import pprint # print data structures prettier\n",
    "import re # regex\n",
    "import requests # request URL content\n",
    "import sys # system operations\n",
    "import time # sleep timer\n",
    "from tqdm import tqdm_notebook # make a nice progressbar\n",
    "import urllib # handle special URL chars\n",
    "\n",
    "# make working directory\n",
    "directory = os.getcwd() + '/companies'\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "# files from data crawling\n",
    "ex1_fdat = directory + '/extraction1_data.pkl'\n",
    "ex2_fdat = directory + '/extraction2_data.pkl'\n",
    "ex3_tmp_fdat = directory + '/tmp_extraction3_data.pkl'\n",
    "ex3_fdat = directory + '/extraction3_data.pkl'\n",
    "merged = directory + '/merged_data.pkl'\n",
    "\n",
    "# network files\n",
    "network_f = directory + '/network.pkl'\n",
    "network_red_f = directory + '/reduced_network.pkl'\n",
    "gephi_f = directory + '/gehpi.gexf'\n",
    "\n",
    "# specify nltk data dir, otherwise LookupError\n",
    "nltk.data.path.append(os.getcwd() + '/../nltk_data')\n",
    "from nltk.corpus import names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Construct the Company Network\n",
    "\n",
    "To construct the network the information that was saved into the pickle file and is reread into a dictionary. Each key represents a company that contains all the extra information as it's value which is also a dictionary, similar to row and column in a table. That way attributes can be attached to each node. The link list is used to connect each node with its neighbors.\n",
    "\n",
    "On an important note, the main reason why the raw dictionary is used is that higher data structures or attribute values can be used. But `None` type objects can lead to problems when exporting to a `gexf` file that can be imported into the visualization tool gephi. In general attributes can only be a fairly simple data types because of the export to XML. It is best to stick to bool, dates, strings and numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net_dat = dict()\n",
    "# load network data if available\n",
    "if os.path.isfile(network_f):\n",
    "    with open(network_f, 'rb') as f:\n",
    "        net_dat = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_graph(com_dat):\n",
    "\n",
    "    # init directed graph object\n",
    "    c_graph = nx.DiGraph()\n",
    "    \n",
    "    # iterate through company data\n",
    "    for c_name, comp in com_dat.iteritems():\n",
    "        \n",
    "        # don't add non companies\n",
    "        if 'is_company' not in comp or not comp['is_company']:\n",
    "            continue\n",
    "\n",
    "        # no None types for gexf file\n",
    "        comp = {k: 'NaN' for k,v in comp.iteritems() if not v}\n",
    "        \n",
    "        lat = 'NaN'\n",
    "        lng = 'NaN'\n",
    "        if comp['location_gps'][0]:\n",
    "            lat = comp['location_gps'][0]\n",
    "        if comp['location_gps'][1]:\n",
    "            lng = comp['location_gps'][1]\n",
    "            \n",
    "        # create one node per company name (keys of data)\n",
    "        c_graph.add_node(\n",
    "            c_name,\n",
    "            name=comp['name'], \n",
    "            type=comp['type'][0], # just first element for lists\n",
    "            industry=comp['industry'][0],\n",
    "            founded=comp['founded'],\n",
    "            location_city=comp['location_city'],\n",
    "            location_country=comp['location_country'],\n",
    "            latitude=lat,\n",
    "            longitude=lng,\n",
    "            defunct=comp['defunct'],\n",
    "            num_employees=comp['num_employees'],\n",
    "            parent=comp['parent']\n",
    "        )\n",
    "\n",
    "        # show example of related company\n",
    "        if c_name == 'Apple Inc.':\n",
    "            print \"Link list of\", c_name, \"company:\\n\", comp['links']\n",
    "\n",
    "        # add an edge for the company, but from the original dictionary\n",
    "        for e in comp['links']:\n",
    "            if e in com_dat and 'is_company' in com_dat[e] and com_dat[e]['is_company']:\n",
    "                c_graph.add_edge(c_name, e)\n",
    "                \n",
    "    return c_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'net_dat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-346df2bd1fc6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0;34m'graph'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnet_dat\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnet_dat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'graph'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mc_graph\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mnet_dat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'graph'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32melif\u001b[0m \u001b[0;34m'raw_dat'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnet_dat\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnet_dat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'raw_dat'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mc_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet_dat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'raw_dat'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'net_dat' is not defined"
     ]
    }
   ],
   "source": [
    "if 'graph' in net_dat and net_dat['graph']:\n",
    "    c_graph =  net_dat['graph']\n",
    "elif 'raw_dat' in net_dat and net_dat['raw_dat']:\n",
    "    c_graph = create_graph(net_dat['raw_dat'])\n",
    "else:\n",
    "    c_graph = create_graph(merged_companies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 57590 nodes in the network.\n",
      "There are 1032557 edges in the network.\n"
     ]
    }
   ],
   "source": [
    "print \"There are {0} nodes in the network.\".format(len(c_graph.nodes()))\n",
    "print \"There are {0} edges in the network.\".format(len(c_graph.edges()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weakly Connected Component\n",
    "\n",
    "The weakly connected component (WCC) is a maximal subgraph of a directed graph such that for every pair of vertices $u$, $v$ in the subgraph, there is an undirected path from $u$ to $v$ and a directed path from $v$ to $u$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_wcc(G):\n",
    "    return sorted(nx.weakly_connected_component_subgraphs(G), key=len, reverse=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if 'wcc' in net_dat and net_dat['wcc']:\n",
    "    c_weak =  net_dat['wcc']\n",
    "else:\n",
    "    c_weak = get_wcc(c_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size (number of edges) of subgraph with largest weakly connected component is: 1031478\n"
     ]
    }
   ],
   "source": [
    "print 'The size (number of edges) of subgraph with largest weakly connected component is:', c_weak.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Degree Centrality\n",
    "\n",
    "Historically first and conceptually simplest is degree centrality, which is defined as the number of links incident upon a node (e.g.: the number of ties that a node has). The degree can be interpreted in terms of the immediate risk of a node for catching whatever is flowing through the network (such as a virus, or some information). In the case of a directed network (where ties have direction), usually two separate measures of degree centrality are defined, namely in-degree and out-degree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def deg_cents(G_wcc):\n",
    "    \"\"\"Get degree centrality.\"\"\"\n",
    "    \n",
    "    # in-edges\n",
    "    node_in_degree = nx.in_degree_centrality(G_wcc)\n",
    "    # out-edges\n",
    "    node_out_degree = nx.out_degree_centrality(G_wcc)\n",
    "    return node_in_degree, node_out_degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if 'deg_cent_in' in net_dat and \\\n",
    "    'deg_cent_out' in net_dat and \\\n",
    "    net_dat['deg_cent_in'] and \\\n",
    "    net_dat['deg_cent_out']:\n",
    "        node_in_degree =  net_dat['deg_cent_in']\n",
    "        node_out_degree =  net_dat['deg_cent_out']\n",
    "else:\n",
    "    node_in_degree, node_out_degree = deg_cents(c_weak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 most central companies according to in-edges degree centrality:\n",
      "[(u'Microsoft', 0.028508823049488333),\n",
      " (u'Reuters', 0.027040257348656144),\n",
      " ('Sony', 0.020489988111610992),\n",
      " ('Google', 0.01934777034429707),\n",
      " (u'IBM', 0.01806568917690389),\n",
      " (u'HSBC', 0.017040024242989345),\n",
      " (u'Vodafone', 0.01678360800951071),\n",
      " (u'Apple Inc.', 0.01673698687615096),\n",
      " (u'Nintendo', 0.01631739667591319),\n",
      " (u'Intel', 0.015897806475675423)]\n",
      "\n",
      "10 most central companies according to out-edges degree centrality:\n",
      "[('Telia Company', 0.012331289773654396),\n",
      " ('Hitachi', 0.012214736940255017),\n",
      " (u'Vodafone', 0.012098184106855637),\n",
      " ('Sony', 0.01191169957341663),\n",
      " ('Panasonic', 0.011398867106459357),\n",
      " (u'Toshiba', 0.011375556539779482),\n",
      " (u'Kyocera', 0.011352245973099605),\n",
      " ('Mitsubishi Electric', 0.010862724072822209),\n",
      " ('Comcast', 0.01074617123942283),\n",
      " ('Fujitsu', 0.010722860672742954)]\n"
     ]
    }
   ],
   "source": [
    "print \"10 most central companies according to in-edges degree centrality:\"\n",
    "pprint(Counter(node_in_degree).most_common(10))\n",
    "\n",
    "print \"\\n10 most central companies according to out-edges degree centrality:\"\n",
    "pprint(Counter(node_out_degree).most_common(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Technology companies have a lead when it comes to most in/out degree centrality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eigen_cents(G_wcc):\n",
    "    \"\"\"Get degree centrality.\"\"\"\n",
    "    \n",
    "    # in-edges\n",
    "    node_in_eigen = nx.eigenvector_centrality(G_wcc)\n",
    "    # out-edges, needs reversed wcc graph\n",
    "    node_out_eigen = nx.eigenvector_centrality(G_wcc.reverse())\n",
    "    return node_in_eigen, node_out_eigen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if 'eigen_cent_in' in net_dat and \\\n",
    "    'eigen_cent_out' in net_dat and \\\n",
    "    net_dat['eigen_cent_in'] and \\\n",
    "    net_dat['eigen_cent_out']:\n",
    "        node_in_eigen =  net_dat['eigen_cent_in']\n",
    "        node_out_eigen =  net_dat['eigen_cent_out']\n",
    "else:\n",
    "    node_in_eigen, node_out_eigen = eigen_cents(c_weak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 most central companies according to in-edges eigenvector centrality:\n",
      "[('Whole Foods Market', 0.06513803920756327),\n",
      " ('Costco', 0.06467179872391232),\n",
      " (u'Lidl', 0.0645838642026889),\n",
      " (u'Aldi', 0.06457330500187025),\n",
      " (u'Albertsons', 0.06457029576072434),\n",
      " (u'Ahold Delhaize', 0.06455900783217165),\n",
      " (u'Giant-Carlisle', 0.06450263306524448),\n",
      " (u'Pavilions (supermarket)', 0.06448307712349564),\n",
      " (u'M\\xe1s Club', 0.06445324850334076),\n",
      " (u'Walmart', 0.06444629182605319)]\n",
      "\n",
      "10 most central companies according to out-edges eigenvector centrality:\n",
      "[(u'Albertsons', 0.06500364713613616),\n",
      " (u'Delhaize Group', 0.06497264344789812),\n",
      " (u'Kroger', 0.06490845641815714),\n",
      " (u'SuperValu (United States)', 0.06471331197720417),\n",
      " ('Costco', 0.06469132155925905),\n",
      " ('Whole Foods Market', 0.06468862077172617),\n",
      " (u'Star Market', 0.06437887738082511),\n",
      " (u'Acme Markets', 0.0643407200103748),\n",
      " (u'Aldi', 0.06432459116870955),\n",
      " (u'Stop & Shop', 0.06431557975668435)]\n"
     ]
    }
   ],
   "source": [
    "print \"10 most central companies according to in-edges eigenvector centrality:\"\n",
    "pprint(Counter(node_in_eigen).most_common(10))\n",
    "\n",
    "print \"\\n10 most central companies according to out-edges eigenvector centrality:\"\n",
    "pprint(Counter(node_out_eigen).most_common(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After seeing the result for eigenvector centrality it was weird that only retail and food companies show up. Once we took a closer look at the article of [Delhaize Group](https://en.wikipedia.org/wiki/Delhaize_Group#See_also) we noted that a lot of external links exists:\n",
    "* Supermarket chains in the United States\n",
    "* Top 20 companies in Belgium (BEL20 companies of Belgium)\n",
    "* etc.\n",
    "\n",
    "Eigenvector centrality is a measure of the influence of a node in a network. It assigns relative scores to all nodes in the network based on the concept that connections to high-scoring nodes contribute more to the score of the node in question than equal connections to low-scoring nodes. Since Delhaize Group has for example Stop & Shop as subsidiary these high eigenvector centrality nodes link to other high eigenvector centrality nodes. \n",
    "\n",
    "Thus the decision was made to exclude the sections:\n",
    "* See also\n",
    "* References \n",
    "* External links\n",
    "\n",
    "They can be useful like in the case of [Microsoft](https://en.wikipedia.org/wiki/Microsoft#External_links) but for the majority these sections are rather misleading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# store network data to file\n",
    "network = {\n",
    "    'graph': c_graph,\n",
    "    'raw_dat': pickle_companies,\n",
    "    'wcc': c_weak,\n",
    "    'deg_cent_in': node_in_degree,\n",
    "    'deg_cent_out': node_out_degree,\n",
    "    'eigen_cent_in': node_in_eigen,\n",
    "    'eigen_cent_out': node_out_eigen\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the file for fast reprocessing\n",
    "with open(network_f, 'wb') as f:\n",
    "    pickle.dump(network, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# free up some memory\n",
    "del network, c_graph, net_dat\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Alternative construction\n",
    "\n",
    "The same strategy as above is used to get the data and construct the network from it. All of the calculations were saved in order to execute the final notebook much faster. There will be less links after rebuilding the network because of the skipped sections. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load network data if available\n",
    "net_dat_red = dict()\n",
    "if os.path.isfile(network_red_f):\n",
    "    with open(network_red_f, 'rb') as f:\n",
    "        net_dat_red = pickle.load(f)\n",
    "if not pickle_companies:\n",
    "    # load data from all extractions\n",
    "    if os.path.isfile(merged):\n",
    "        with open(merged, 'rb') as f:\n",
    "            pickle_companies = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to rebuild the whole network the wikitext is reparsed while the problematic sections are cut from the string. The current link list will then be intersected with the new list of all links on the page that is cross checked with the list of all links that were returned by the Wikipedia API.\n",
    "\n",
    "This new list of links will also be populated to the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any link in sections without [u'==See also==', u'==References==', u'==External links=='] :\n",
      "set([u'Naamloze vennootschap', u'Alfa-Beta Vassilopoulos', u'Ahold Delhaize', u'Mega Image', u'Sweetbay Supermarket', u'Ahold', u'Dick Boer', u'Aldi', u'Hannaford Brothers Company', u'Cub Foods', u'Louis Delhaize Group', u'REWE Group', u'Food Lion LLC', u'BI-LO (United States)', u'Mats Jansson', u'Belgium', u'Brussels', u'Indonesia', u'Frans Muller', u'Zellik', u\"Kash n' Karry\", u'Charleroi', u'Billa (supermarket)', u'Maxi (Serbian supermarket)', u'Anderlecht', u'Sint-Jans-Molenbeek', u'S.A. (corporation)', u'Food Lion']) \n",
      "\n",
      "All company links, all sections:\n",
      "set([u'Strack & Van Til', u'Acme Markets', u'Inditex', u'UCB (company)', u'Price Chopper Supermarkets', u'Cash & Carry', u'Jer\\xf3nimo Martins', u'Quality Dairy Company', u'Cofinimmo', u'Quality Markets', u'Xpect Discounts', u'Omni Superstore', u'H&M', u'Uwajimaya', u'Food City (K-VA-T)', u'Target Corporation', u'Harris Teeter', u'Ampm', u'Rouses', u'OXXO', u'Ackermans & van Haaren', u'Carrefour City', u'Times Supermarkets', u\"Redner's Markets\", u'Key Food', u'Asda', u\"Heinen's Fine Foods\", u'Alpha Beta', u'Sweetbay Supermarket', u\"Weigel's\", u'Hannaford Brothers Company', u'Albertsons', u\"Ridley's Family Markets\", u'Stripes Convenience Stores', u'Ralphs', u'United Grocery Outlet', u'Simon David', u'Tops Friendly Markets', u\"David's Supermarkets\", u'Central Market (Texas)', u'King Kullen', u\"Seessel's\", u'Irving Oil', u'Bristol Farms', u\"Owen's Market\", u'Wegmans', u'Albert Heijn', u'Miracle Mart (North Dakota)', u'Sasol', u\"Dominick's\", u'Umicore', u\"Kuhn's Quality Foods\", u'C&A', u'Piggly Wiggly Carolina Co.', u'Roche Bros.', u'Seafood City', u'GetGo', u'L&F Jones', u'Earth Fare', u'QuikTrip', u'Marks & Spencer', u'H Mart', u'Acme Fresh Market', u\"Petrini's\", u\"Dave's Markets\", u'Lawson (store)', u'Bargain Booze', u\"Genuardi's\", u'Sunflower Market', u'New Deal Supermarket', u'Plus (supermarket)', u'Sheetz', u\"Stew Leonard's\", u'Befimmo', u'ParknShop', u'Finast', u\"Carter's Foods\", u'NightOwl Convenience Stores', u'Tom Thumb Food & Pharmacy', u'Carrs-Safeway', u'Aldi', u'The Fresh Grocer', u'Red Food', u'Alfamart', u'Haggen', u'Marina Food', u'David Sands', u'New Seasons Market', u'Laneco', u'Amigo Supermarkets', u\"Waldbaum's\", u\"McColl's\", u'CST Brands', u'Gull Petroleum', u\"Ukrop's Food Group\", u'Wakefern Food Corporation', u'Harveys Supermarkets', u'Dierbergs Markets', u\"Shaw's and Star Market\", u'Dorothy Lane Market', u\"Rutter's\", u'Market Basket', u\"Jerry's Foods\", u'Fisher Foods', u'Vons', u'Ingles', u'Ministop', u'The Food Emporium', u'United Dairy Farmers', u'Jr. Food Stores', u'Safeway Inc.', u'Whole Foods Market', u'M\\xe1s Club', u\"Mac's Convenience Stores\", u'Soriana', u'ShopRite (United States)', u'Best-One', u\"Roundy's\", u'Dari Mart', u'Fresh Mart', u'Pingo Doce', u'Bekaert', u'Nijiya Market', u'Fairway Market', u\"Sendik's Food Market\", u'Peapod', u'Best Yet Market', u'Dean & DeLuca', u'Harmons', u\"Becker's\", u\"Andronico's\", u\"Zabar's\", u'FamilyMart', u'Econofoods', u'Metro AG', u'Westborn Market', u\"Hornbacher's\", u'Daily Stop', u'Eisner Food Stores', u'Kwik Shop', u'Nisa (retailer)', u'Jacksons Stores', u'Houchens Industries', u'Kroger', u'Circle K Sunkus', u'Colruyt Group', u'Food Lion', u'Spar (retailer)', u'Woolworths Limited', u'US Foods', u'NewsLink', u'Giant Eagle', u'PCC Natural Markets', u'Lidl', u'Centra', u'Elia System Operator', u'Minyard Food Stores', u'Lion Supermarket', u'SpartanNash', u\"Bashas'\", u'Winn-Dixie', u'American Stores', u'The Fresh Market', u'Southern Family Markets', u'Food Basics USA', u'Buehler Food Markets Inc.', u'Getty Oil', u'Food 4 Less', u'Mars (supermarket)', u'Chevron Corporation', u\"Scott's Food & Pharmacy\", u'Wawa Inc.', u'Minit Mart Foods Inc.', u'White Hen Pantry', u\"Johnnie's Foodmaster\", u'Bpost', u'Hy-Vee', u'Mercadona', u'Ahold', u'PriceRite', u'Piggly Wiggly', u'Foodtown (United States)', u\"Fry's Food and Drug\", u\"Casey's General Stores\", u'Gate Petroleum', u\"BJ's Wholesale Club\", u'Walmart', u'Franprix', u\"Buc-ee's\", u'Save-A-Lot', u'D&W Fresh Market', u'Londis (Ireland)', u'Delchamps', u'Scotmid', u'Western Beef', u\"Sam's Club\", u'Penn Traffic', u'United Refining Company', u\"Shop 'n Save\", u\"Roady's Truck Stops\", u\"Martin's Super Markets\", u'Telenet (Belgium)', u'Harps Food Stores', u'Red Owl (retail chain)', u'Publix', u'Ahold Delhaize', u'Budgens', u'Mi Pueblo Food Center', u'Island Pacific Supermarket', u'Lowes Foods', u'Family Fare', u'Pink Dot', u'QFC', u\"Dahl's Foods\", u'Davis Food City', u'Big Y', u\"Tidyman's\", u\"Trader Joe's\", u'City Market (US grocery store chain)', u'Big C', u'Quick Chek', u'Proximus Group', u'Mace (store)', u'Plaid Pantry', u'108 Shop', u'759 Store', u'Tesco', u'Delek', u'Alfa-Beta Vassilopoulos', u'Market of Choice', u'Londis (United Kingdom)', u'Tesco Lotus', u'Alimentation Couche-Tard', u\"Stuckey's\", u'Pilot Flying J', u'BI-LO (United States)', u\"Gelson's Markets\", u'Costco', u'Groupe Bruxelles Lambert', u\"Magruder's\", u'Remke Markets', u'Jewel (supermarket)', u'Ruler Foods', u'Convenient Food Mart', u'Mitsuwa Marketplace', u'Felpausch', u'JayC Food Stores', u'Belle Foods', u'Gristedes', u\"Henry's Farmers Market\", u'Pathmark', u'CHS Inc.', u'Pavilions (supermarket)', u'Tiendas Extra', u'Star Market', u'SuperAmerica', u'Dillons', u'Skaggs Companies', u\"Smith's Food and Drug\", u'Giant-Landover', u'Grocery Outlet', u'Gerland Corporation', u'Victory Supermarkets', u'Groszek', u'Etos', u\"Stewart's Shops\", u'Weis Markets', u'Kingfisher plc', u'Sellers Bros.', u'Stop & Shop/Giant-Landover', u'Maxi (Serbian supermarket)', u'Carrefour', u'Engie', u'Petronas', u'Jiffy (convenience store)', u'Jr. Food Mart', u'Pioneer Energy', u'The Great Atlantic & Pacific Tea Company', u'Akwa Group', u'El Corte Ingl\\xe9s', u'Grand Union (supermarket)', u'Save Mart Supermarkets', u'King Soopers', u'Kings Food Markets', u'Pay Less Super Markets', u'County Market', u'7-Eleven', u'Clark Brands', u'Sunflower Farmers Market', u'H-E-B', u\"Bruno's\", u'Pick-N-Pay Supermarkets', u'Rosauers Supermarkets', u'Meijer', u'Buttrey Food & Drug', u\"Tom's Convenience Store\", u\"Boyer's Food Markets, Inc.\", u\"Raley's Supermarkets\", u'Smart & Final', u'Cub Foods', u\"Love's Travel Stops & Country Stores\", u'Pressbyr\\xe5n', u'Fareway', u'Cumberland Farms', u'Poplar (convenience store)', u'Lewis Food Town', u\"Scolari's Food and Drug\", u'WinCo Foods', u'Waitrose', u'Super Saver Foods', u'Brookshire Grocery Company', u'Billa (supermarket)', u'IGA (supermarkets)', u'Marsh Supermarkets', u'DeMoulas Market Basket', u'RaceTrac', u'All Day Convenience Store', u'IKEA', u'KBC Bank', u'Indomaret', u\"Mollie Stone's Markets\", u\"Hugo's\", u'Farm Fresh Food & Pharmacy', u\"Baker's Supermarkets\", u'Somerfield', u\"Marc's\", u'Marukai Corporation U.S.A.', u\"Balducci's\", u\"Glen's Markets\", u'Festival Foods', u\"Woodman's Markets\", u'Lucky Stores', u'Pueblo Supermarkets', u'Thorntons Inc.', u'Niemann Foods', u'Stater Bros.', u'Shinsegae', u'Big Bear Stores', u'La Perla Tapat\\xeda Supermarkets', u'Giant-Carlisle', u'Ageas', u'TravelCenters of America', u'Kwik Trip', u'Stop & Shop', u'Brookshire Brothers', u'Anheuser-Busch InBev', u'Southeastern Grocers', u'Kessel Food Markets', u'CBA (food retail)', u'Seven Mile Market', u\"Allsup's\", u'Costcutter', u'Warehouse Economy Outlet', u\"Randall's Food Markets\", u'Groupe Casino', u'Marketside', u'SuperValu (United States)', u'China Resources Vanguard', u\"Shop 'n Save (Pittsburgh)\", u'Shoppers Food & Pharmacy', u'Road Ranger', u'Kum & Go', u'Met Foods', u'Schnucks', u'Hamady Brothers', u'Farmer Jack', u'Ahold Czech Republic', u'Super Fresh', u'Fresh & Easy', u'Murphy USA', u'Fred Meyer', u'Super One Foods', u'Louis Delhaize Group', u'Circle K', u'REWE Group', u\"Zupan's Markets\", u'Nugget Markets', u\"Reid's\", u'Fiesta Mart', u'Speedway LLC', u'Bottom Dollar Food', u'Bloom (store)', u'Sprouts Farmers Market', u'United Supermarkets', u'Local Plus', u'99 Ranch Market', u'Foodland Hawaii', u'Eagle Food Centers', u'Ma\\u0142pka Express', u'Kwik Save', u'Tedeschi Food Shops', u\"Yoke's Fresh Market\", u'Wild Oats Markets', u'European Retail Round Table', u'Grand Mart', u'NTUC FairPrice']) \n",
      "\n",
      "Final company links without unwanted sections:\n",
      "set([u'REWE Group', u'Billa (supermarket)', u'Maxi (Serbian supermarket)', u'Ahold Delhaize', u'Alfa-Beta Vassilopoulos', u'BI-LO (United States)', u'Sweetbay Supermarket', u'Ahold', u'Aldi', u'Hannaford Brothers Company', u'Food Lion', u'Cub Foods', u'Louis Delhaize Group']) \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for c_name, comp in tqdm_notebook(pickle_companies.iteritems(), desc='Links'):\n",
    "\n",
    "    # don't add non companies\n",
    "    if 'is_company' not in comp or not comp['is_company']:\n",
    "        continue\n",
    "    \n",
    "    # parse wikitext, remove references\n",
    "    wiki_raw_cleaned = re.sub(r'<ref.+?</ref>|<ref>.+?</ref>', '', comp['wiki_raw'])\n",
    "    wiki_code = mwparserfromhell.parse(wiki_raw_cleaned, skip_style_tags=True)\n",
    "    exclude_sections = [u'==See also==', u'==References==', u'==External links==']\n",
    "    # cut the raw wiki text at the found section\n",
    "    for e in exclude_sections:\n",
    "        if e in wiki_code.filter_headings():\n",
    "            # take the first part of the wikicode excluding the unwanted section\n",
    "            wiki_raw_cleaned = wiki_raw_cleaned.split(e)[0]\n",
    "\n",
    "    wiki_code = mwparserfromhell.parse(wiki_raw_cleaned, skip_style_tags=True)\n",
    "    # go through each link in wikitext and extract\n",
    "    links = set()\n",
    "    for link in wiki_code.filter_wikilinks():\n",
    "        # [[Template:Infobox company]]\n",
    "        if re.match(r'\\[\\[.+:.+\\]\\]', unicode(link)):\n",
    "            continue\n",
    "        # [[T\\xe4by]], [[Hertz|MHz]]\n",
    "        matched_wiki_name = re.match(r'\\[\\[(.+?)(?:\\|.+)?\\]\\]', unicode(link))\n",
    "        if matched_wiki_name:\n",
    "            if matched_wiki_name.group(1) in comp['all_links']:\n",
    "                links.add(matched_wiki_name.group(1))\n",
    "\n",
    "    if c_name == 'Delhaize Group':\n",
    "        print \"Any link in sections without\", exclude_sections, \":\\n\", links, \"\\n\"\n",
    "        print \"All company links, all sections:\\n\", comp['links'], \"\\n\"\n",
    "        comp['links'] = comp['links'].intersection(links)\n",
    "        print \"Final company links without unwanted sections:\\n\", comp['links'], \"\\n\"\n",
    "\n",
    "    # list of links from specific sections intersected with old link list\n",
    "    comp['links'] = comp['links'].intersection(links)\n",
    "    comp['all_links'] = links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Link list of Apple Inc. company:\n",
      "{T-Systems, American Airlines Group, Bharat Sanchar Nigam Limited, Tata Teleservices, FingerWorks, Amgen, Yves Saint Laurent (brand), Huawei, Reuters, Applied Materials, Comcast, IBM Global Services, Deloitte, Biogen, Condé Nast, Sanmina Corporation, Vodafone, Statista, Samsung Electronics, Sony, Olympus Corporation, HP Inc., Shire (pharmaceutical company), Nokia, Xerox, Rakuten, UL (safety organization), American Express, Booz Allen Hamilton, Alphabet Inc., Casio, MediaTek, The Priceline Group, CA Technologies, NTT DATA, Burberry, China Unicom, Interbrand, PARC (company), KDDI, Cerner, Jabil Circuit, Silicon Power, Konica Minolta, Dentsply Sirona, IBM, Boston Consulting Group, Leidos, Canon Inc., Asus, KPMG, SanDisk, NeXT, Bharti Airtel, Adobe Systems, Plextor, Whole Foods Market, Fiserv, SAP SE, Costco, América Móvil, China Mobile, Liberty Interactive, BBK Electronics, Xilinx, Dollar Tree, Omnicom Group, Wistron Corporation, Chevron Corporation, DuPont, Tesla Motors, Pegatron, Hitachi Data Systems, Accenture, Cognizant, The Travelers Companies, Infosys, Semiconductor Manufacturing International Corporation, Sun Microsystems, Hewlett Packard Enterprise Services, Paccar, STMicroelectronics, Beats Electronics, Dell Technologies, LG Electronics, Nippon Telegraph and Telephone, FileMaker Inc., Star Micronics, Dish Network, China Telecom, EMI, Ulta Beauty, Fujifilm, Inspur, Hitachi Consulting, Ricoh, BlackBerry Limited, Meizu, 3M, Incyte, ...}\n"
     ]
    }
   ],
   "source": [
    "if 'graph' in net_dat_red and net_dat_red['graph']:\n",
    "    c_graph_reduced =  net_dat_red['graph']\n",
    "else:\n",
    "    c_graph_reduced = create_graph(companies_df, pickle_companies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 57416 nodes in the network.\n",
      "There are 147403 edges in the network.\n"
     ]
    }
   ],
   "source": [
    "print \"There are {0} nodes in the network.\".format(len(c_graph_reduced.nodes()))\n",
    "print \"There are {0} edges in the network.\".format(len(c_graph_reduced.edges()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the size of the number of links decreased dramatically from over a million to ca. 150 thousand. That is only 15% of the original links."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weakly Connected Component\n",
    "\n",
    "The first two steps of creating the WCC and calculating some centralities will be like above. However new centrality measures are introduced and evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if 'wcc' in net_dat_red and net_dat_red['wcc']:\n",
    "    c_weak_red =  net_dat_red['wcc']\n",
    "else:\n",
    "    c_weak_red = get_wcc(c_graph_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size (number of edges) of subgraph with largest weakly connected component is: 146005\n"
     ]
    }
   ],
   "source": [
    "print 'The size (number of edges) of subgraph with largest weakly connected component is:', c_weak_red.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Degree Centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if 'deg_cent_in' in net_dat_red and \\\n",
    "    'deg_cent_out' in net_dat_red and \\\n",
    "    net_dat_red['deg_cent_in'] and \\\n",
    "    net_dat_red['deg_cent_out']:\n",
    "        node_in_degree =  net_dat_red['deg_cent_in']\n",
    "        node_out_degree =  net_dat_red['deg_cent_out']\n",
    "else:\n",
    "    node_in_degree, node_out_degree = deg_cents(c_weak_red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 most central companies according to in-edges degree centrality:\n",
      "[(u'Microsoft', 0.02304040456163889),\n",
      " (u'IBM', 0.014448629960266269),\n",
      " (u'Google', 0.013313380463388204),\n",
      " (u'Apple Inc.', 0.011610506218071108),\n",
      " (u'Sony', 0.01093967696991589),\n",
      " (u'General Motors', 0.010294648846689717),\n",
      " (u'Intel', 0.009520615098818309),\n",
      " (u'BBC', 0.00884978585066309),\n",
      " (u'General Electric', 0.008823984725734042),\n",
      " (u'Hewlett-Packard', 0.008617575726301667)]\n",
      "\n",
      "10 most central companies according to out-edges degree centrality:\n",
      "[(u'Sony Interactive Entertainment', 0.002554311367975644),\n",
      " (u'General Motors', 0.0023221012436142217),\n",
      " ('Electronic Arts', 0.0021156922441818464),\n",
      " ('The Blackstone Group', 0.0020898911192527994),\n",
      " ('Participant Media', 0.0020640899943237525),\n",
      " (u'Bain Capital', 0.0020382888693947056),\n",
      " (u'Vodafone', 0.0020124877444656587),\n",
      " ('Kohlberg Kravis Roberts', 0.0019092832447494712),\n",
      " ('Sega development studios', 0.0019092832447494712),\n",
      " ('Dell', 0.0018576809948913774)]\n"
     ]
    }
   ],
   "source": [
    "print \"10 most central companies according to in-edges degree centrality:\"\n",
    "pprint(Counter(node_in_degree).most_common(10))\n",
    "\n",
    "print \"\\n10 most central companies according to out-edges degree centrality:\"\n",
    "pprint(Counter(node_out_degree).most_common(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example Microsoft, Google and Apple still appear in the top 10 of degree centrality after the approach of the network generation was shifted. Now there is also a greater mix with not only technology companies.\n",
    "\n",
    "First we also had Los Angeles Times and Reuters under the top 10 of degree centrality but that was mainly due to the fact of HTML markup in the reference links, thus it's important to remove it. For example there is a reference in Ford Motor company auoted from the Los Angeles Times.\n",
    "\n",
    "```\n",
    "Following international condemnation of [[apartheid]], Ford divested from South Africa in 1988, and sold its stake in Samcor, although it licensed the use of its brand name to the company.<ref>{{cite news |url=http://articles.latimes.com/1987-06-15/business/fi-4242_1_south-africa |title=Ford Discussing Plans to Divest in South Africa : Firm Would Give 24% Stake to Workers, But Maintain a Presence |first1=Ralph |last1=Vartabedian |first2=Michael |last2=Parks |work=[[Los Angeles Times]] |date=June 15, 1987 |access-date=October 14, 2016}}</ref>\n",
    "```\n",
    "\n",
    "So you can see a lot can be influenced by the way the data is gained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eigenvector Centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if 'eigen_cent_in' in net_dat_red and \\\n",
    "    'eigen_cent_out' in net_dat_red and \\\n",
    "    net_dat_red['eigen_cent_in'] and \\\n",
    "    net_dat_red['eigen_cent_out']:\n",
    "        node_in_eigen =  net_dat_red['eigen_cent_in']\n",
    "        node_out_eigen =  net_dat_red['eigen_cent_out']\n",
    "else:\n",
    "    node_in_eigen, node_out_eigen = eigen_cents(c_weak_red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 most central companies according to in-edges eigenvector centrality:\n",
      "[(u'Paramount Pictures', 0.28106553034599246),\n",
      " (u'Warner Bros.', 0.25732362996988983),\n",
      " ('Metro-Goldwyn-Mayer', 0.2240955539474639),\n",
      " (u'Columbia Pictures', 0.21100595923026386),\n",
      " ('Universal Studios', 0.204660784489684),\n",
      " (u'20th Century Fox', 0.20333262023268336),\n",
      " (u'The Walt Disney Company', 0.20320112709323326),\n",
      " (u'Time Warner', 0.1640586114291285),\n",
      " (u'Viacom', 0.15661508566370816),\n",
      " ('United Artists', 0.14660895245000108)]\n",
      "\n",
      "10 most central companies according to out-edges eigenvector centrality:\n",
      "[(u'Paramount Pictures', 0.14370457689279156),\n",
      " (u'Warner Bros.', 0.13161381487598867),\n",
      " ('Metro-Goldwyn-Mayer', 0.13070336490021245),\n",
      " ('HBO', 0.12775966719546544),\n",
      " (u'StudioCanal', 0.12066477317198789),\n",
      " ('Participant Media', 0.11848770471897913),\n",
      " ('Sony Pictures Worldwide Acquisitions', 0.11720214747344199),\n",
      " (u'PolyGram Filmed Entertainment', 0.11621287309973505),\n",
      " (u'Screen Gems', 0.11551202241555811),\n",
      " ('MGM Home Entertainment', 0.1124724137019677)]\n"
     ]
    }
   ],
   "source": [
    "print \"10 most central companies according to in-edges eigenvector centrality:\"\n",
    "pprint(Counter(node_in_eigen).most_common(10))\n",
    "\n",
    "print \"\\n10 most central companies according to out-edges eigenvector centrality:\"\n",
    "pprint(Counter(node_out_eigen).most_common(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From retail and food stores the eigenvector centrality changed to entertainment companies. \n",
    "\n",
    "TODO: WHY?\n",
    "\n",
    "Furthermore, there is a high number of technology corporations that generally have a high number "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Links of Paramount Pictures are:\n",
      "[u'First National Pictures', u'Universal Studios', u'Fleischer Studios', u'Platinum Dunes', u'Viacom Productions', u'CBS Home Entertainment', u'Gulf and Western Industries', u'Gary Sanchez Productions', u'Metro-Goldwyn-Mayer', u'The Walt Disney Company', u'Viacom (original)', u'Walt Disney Studios (division)', u'CBS Television Stations', u'DAMAC Properties', u'Nordisk Film', u'Wanda Group', u'Paramount Television', u'Di Bonaventura Pictures', u'Paramount Home Media Distribution', u'NBCUniversal', u'DreamWorks', u'Universal Music Group', u'Famous Players', u'Viacom Media Networks', u'Fake Empire Productions', u'CBS Television Distribution', u'Bad Robot Productions', u'Paramount Stations Group', u'Sony/ATV Music Publishing', u'Capital Cities Communications', u'Skydance Media', u'Cedar Fair', u'Comedy Central Films', u'DreamWorks Animation', u'Image Entertainment', u'Paramount Famous Productions', u'United International Pictures', u'Republic Pictures', u'Spelling Television', u'Famous Players Film Company', u'Gaumont Film Company', u'MTV Films', u'Rysher Entertainment', u'Walt Disney Studios Motion Pictures', u'Lucasfilm', u'Paramount Parks', u'Nickelodeon Movies', u'Warner Bros.', u'Worldvision Enterprises', u'Paramount Domestic Television', u'Plan B Entertainment', u'Paramount Vantage', u'Cruise/Wagner Productions', u'MCA Inc.', u'Marvel Studios', u'Insurge Pictures', u'Famous Studios', u'Cineplex Odeon Corporation', u'National Amusements', u'Paramount Animation', u'The Montecito Picture Company', u'Columbia Pictures', u'Desilu Productions', u'20th Century Fox', u'List of Paramount executives', u'CBS Television Studios', u'Viacom', u'Chris-Craft Industries', u'RKO Pictures']\n"
     ]
    }
   ],
   "source": [
    "node = 'Paramount Pictures'\n",
    "print \"Links of\", node, \"are:\\n\", c_graph_reduced.neighbors(node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Betweenness Centrality\n",
    "\n",
    "Betweenness is a centrality measure of a node within a graph. Betweenness centrality quantifies the number of times a node acts as a bridge along the shortest path between two other nodes. Compared to eigenvector centrality which accounts for the 'importance' of a node by taking into account the 'importance' of nodes to which it is pointing to (out-edges) or which are pointing at the node (in-edges) it takes a much longer time to compute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-29-4413a934fd58>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-29-4413a934fd58>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    if 'bet_cent' in net_dat_red and     net_dat_red['bet_cent'] and         node_cent =  net_dat_red['bet_cent']\u001b[0m\n\u001b[0m                                                                                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "if 'bet_cent' in net_dat_red and \\\n",
    "    net_dat_red['bet_cent']:\n",
    "        node_cent =  net_dat_red['bet_cent']\n",
    "else:\n",
    "    node_cent = nx.betweenness_centrality(c_weak_red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 most central company according to betweenness centrality:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'node_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-9cea47d78728>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# use to print with betweenness_centrality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Top 10 most central company according to betweenness centrality:\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_common\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'node_dict' is not defined"
     ]
    }
   ],
   "source": [
    "print \"Top 10 most central company according to betweenness centrality:\"\n",
    "pprint(Counter(node_cent).most_common(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Closeness Centrality\n",
    "\n",
    "Closeness centrality is a measure that wasn't introduced in the [course](http://kurser.dtu.dk/course/02805) curriculum but we wanted to know more about it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some of the measures below an undirected version of the graph was created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if 'wcc_undir' in net_dat_red and net_dat_red['wcc_undir']:\n",
    "    c_weak_red_undir =  net_dat_red['wcc_undir']\n",
    "else:\n",
    "    # create undirected version of the network\n",
    "    c_weak_red_undir = c_weak_red.to_undirected()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Communities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modularity with Louvain algorithm:\n",
      "0.683384508912\n",
      "Number of communities found by Louvain algorithm:\n",
      "66\n"
     ]
    }
   ],
   "source": [
    "# compute the best partition\n",
    "partition = community.best_partition(c_weak_red_undir)\n",
    "\n",
    "# report modularity\n",
    "print \"Modularity with Louvain algorithm:\"\n",
    "print community.modularity(partition, c_weak_red_undir)\n",
    "\n",
    "# report number of communities\n",
    "print \"Number of communities found by Louvain algorithm:\"\n",
    "print len(set(partition.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def findCommunities(G):\n",
    "    \"\"\"\n",
    "    Partition network with the Infomap algorithm.\n",
    "    Annotates nodes with 'community' id and return number of communities found.\n",
    "    \"\"\"\n",
    "\n",
    "    infomapWrapper = infomap.Infomap(\"--two-level\")\n",
    "    for e in G.edges_iter():\n",
    "        infomapWrapper.addLink(*e)\n",
    "\n",
    "    infomapWrapper.run();\n",
    "    tree = infomapWrapper.tree\n",
    "    communities = {}\n",
    "    for node in tree.leafIter():\n",
    "        communities[node.originalLeafIndex] = node.moduleIndex()\n",
    "\n",
    "    nx.set_node_attributes(G, 'community', communities)\n",
    "    return tree.numTopModules()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of communities found by Infomap algorithm: 2071\n"
     ]
    }
   ],
   "source": [
    "# the infomap function only accepts integers as node names\n",
    "c_weak_red_infomap = nx.convert_node_labels_to_integers(c_weak_red_undir)\n",
    "print \"Number of communities found by Infomap algorithm:\", findCommunities(c_weak_red_infomap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# store network data to file\n",
    "network_red = {\n",
    "    'graph': c_graph_reduced,\n",
    "    'raw_dat': pickle_companies,\n",
    "    'clean_dat': companies_df,\n",
    "    'wcc': c_weak_red,\n",
    "    'deg_cent_in': node_in_degree,\n",
    "    'deg_cent_out': node_out_degree,\n",
    "    'eigen_cent_in': node_in_eigen,\n",
    "    'eigen_cent_out': node_out_eigen,\n",
    "    #'bet_cent': node_cent,\n",
    "    'wcc_undir': c_weak_red_undir\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the file for fast reprocessing\n",
    "with open(network_red_f, 'wb') as f:\n",
    "    pickle.dump(network_red, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# produces a file that can be imported into the Gephi network visualization tool\n",
    "nx.write_gexf(c_graph_reduced, gephi_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## What if?\n",
    "\n",
    "What if google disappears and all nodes connecting directly to google with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
